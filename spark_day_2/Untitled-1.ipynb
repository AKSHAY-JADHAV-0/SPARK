{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading: User-Defined Schema (UDS) for DSL and SQL**\n",
    "\n",
    "How to Define and Enforce a User-Defined Schema in PySpark?\n",
    "\n",
    "In this reading, you will learn how to define and enforce a user-defined schema in PySpark.\n",
    "\n",
    "Spark provides a structured data processing framework that can define and enforce schemas for various data sources, including CSV files. Let's look at the steps to define and use a user-defined schema for a CSV file in PySpark:\n",
    "\n",
    "Step 1:\n",
    "\n",
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, IntegerType, FloatType, StringType, StructField"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:**\n",
    "\n",
    "Define the schema.\n",
    "\n",
    "Understanding the data before defining a schema is an important step.\n",
    "\n",
    "Let's take a look at the step-by-step approach to understanding the data and defining an appropriate schema for a given input file:\n",
    "\n",
    "Explore the data: Understand the different data types present in each column.\n",
    "\n",
    "Column data types: Determine the appropriate data types for each column based on your observed values.\n",
    "\n",
    "Define the schema: Use the 'StructType' class in Spark and create a 'StructField' for each column, mentioning the column name, data type, and other properties.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"Emp_Id\", StringType(), False),\n",
    "    StructField(\"Emp_Name\", StringType(), False),\n",
    "    StructField(\"Department\", StringType(), False),\n",
    "    StructField(\"Salary\", IntegerType(), False),\n",
    "    StructField(\"Phone\", IntegerType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'False' indicates null values are NOT allowed for the column.\n",
    "\n",
    "The schema defined above can be utilized for the below CSV file data:\n",
    "\n",
    "Filename: employee.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_id,emp_name,dept,salary,phone\n",
    "A101,jhon,computer science,1000,+1 (701) 846 958\n",
    "A102,Peter,Electronics,2000,\n",
    "A103,Micheal,IT,2500,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Read the input file with user-defined schema.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe on top a csv file\n",
    "df = (spark.read\n",
    "  .format(\"csv\")\n",
    "  .schema(schema)\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"employee.csv\")\n",
    ")\n",
    "# display the dataframe content\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Use the printSchema() method in Spark to display the schema of a DataFrame and ensure that the schema is applied correctly to the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
