{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25e920f-02ee-411c-8988-a705a5be0e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyspark==3.1.2 -q\n",
    "!pip install findspark -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25e780d-9f36-49ae-ba22-dde5c4dc37c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# import SparkSession\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40c3bad-eeff-4ec6-b86c-b739b91a4cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/12 11:03:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"my-spark-app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652d0ed9-d3fe-4db5-b9bd-309671648d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyterlab-jadhavaksha3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>my-spark-app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f639e3f0a10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b15035a-8b2a-4ec7-8bb2-6e8e2d01d6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-12 11:04:41--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/mpg.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13891 (14K) [text/csv]\n",
      "Saving to: ‘mpg.csv’\n",
      "\n",
      "mpg.csv             100%[===================>]  13.57K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-12 11:04:41 (52.4 MB/s) - ‘mpg.csv’ saved [13891/13891]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/mpg.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2272085-5203-470c-b6a1-42c47d2eb8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# using the spark.read.csv function we load the data into a dataframe.\n",
    "# the header = True mentions that there is a header row in out csv file\n",
    "# the inferSchema = True, tells spark to automatically find out the data types of the columns.\n",
    "\n",
    "# Load mpg dataset\n",
    "mpg_data = spark.read.csv(\"mpg.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1798a90-2d0a-4585-a00d-583d9017e444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MPG: double (nullable = true)\n",
      " |-- Cylinders: integer (nullable = true)\n",
      " |-- Engine Disp: double (nullable = true)\n",
      " |-- Horsepower: integer (nullable = true)\n",
      " |-- Weight: integer (nullable = true)\n",
      " |-- Accelerate: double (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44134f3e-f0ef-410f-9179-107442001485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----------+----------+------+----------+----+--------+\n",
      "| MPG|Cylinders|Engine Disp|Horsepower|Weight|Accelerate|Year|  Origin|\n",
      "+----+---------+-----------+----------+------+----------+----+--------+\n",
      "|15.0|        8|      390.0|       190|  3850|       8.5|  70|American|\n",
      "|21.0|        6|      199.0|        90|  2648|      15.0|  70|American|\n",
      "|18.0|        6|      199.0|        97|  2774|      15.5|  70|American|\n",
      "|16.0|        8|      304.0|       150|  3433|      12.0|  70|American|\n",
      "|14.0|        8|      455.0|       225|  3086|      10.0|  70|American|\n",
      "|15.0|        8|      350.0|       165|  3693|      11.5|  70|American|\n",
      "|18.0|        8|      307.0|       130|  3504|      12.0|  70|American|\n",
      "|14.0|        8|      454.0|       220|  4354|       9.0|  70|American|\n",
      "|15.0|        8|      400.0|       150|  3761|       9.5|  70|American|\n",
      "|10.0|        8|      307.0|       200|  4376|      15.0|  70|American|\n",
      "|15.0|        8|      383.0|       170|  3563|      10.0|  70|American|\n",
      "|11.0|        8|      318.0|       210|  4382|      13.5|  70|American|\n",
      "|10.0|        8|      360.0|       215|  4615|      14.0|  70|American|\n",
      "|15.0|        8|      429.0|       198|  4341|      10.0|  70|American|\n",
      "|21.0|        6|      200.0|        85|  2587|      16.0|  70|American|\n",
      "|17.0|        8|      302.0|       140|  3449|      10.5|  70|American|\n",
      "| 9.0|        8|      304.0|       193|  4732|      18.5|  70|American|\n",
      "|14.0|        8|      340.0|       160|  3609|       8.0|  70|American|\n",
      "|22.0|        6|      198.0|        95|  2833|      15.5|  70|American|\n",
      "|14.0|        8|      440.0|       215|  4312|       8.5|  70|American|\n",
      "+----+---------+-----------+----------+------+----------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efc333b-987c-4054-844a-47c6402ed896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MPG=15.0, Cylinders=8, Engine Disp=390.0, Horsepower=190, Weight=3850, Accelerate=8.5, Year=70, Origin='American'),\n",
       " Row(MPG=21.0, Cylinders=6, Engine Disp=199.0, Horsepower=90, Weight=2648, Accelerate=15.0, Year=70, Origin='American'),\n",
       " Row(MPG=18.0, Cylinders=6, Engine Disp=199.0, Horsepower=97, Weight=2774, Accelerate=15.5, Year=70, Origin='American'),\n",
       " Row(MPG=16.0, Cylinders=8, Engine Disp=304.0, Horsepower=150, Weight=3433, Accelerate=12.0, Year=70, Origin='American'),\n",
       " Row(MPG=14.0, Cylinders=8, Engine Disp=455.0, Horsepower=225, Weight=3086, Accelerate=10.0, Year=70, Origin='American')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3391df68-53ca-4500-88e7-03d5a0950d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SparkSession.stop of <pyspark.sql.session.SparkSession object at 0x7f639e3f0a10>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
